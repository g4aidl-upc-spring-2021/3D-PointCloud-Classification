{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PointNet Classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4MmFozKMPk4x",
        "outputId": "f87eb146-3214-4532-e50b-0d1878429d74"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat Jun 26 16:51:39 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.27       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   69C    P0    31W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNMWJ1XHSzXR",
        "outputId": "e2bb41bc-9661-43d4-a5d5-fca89164453e"
      },
      "source": [
        "!python -c \"import torch; print(torch.version.cuda)\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nja0XjwDS6qe",
        "outputId": "ec61fbc9-afe7-4859-ea42-cc936a4e0a9f"
      },
      "source": [
        "!python -c \"import torch; print(torch.__version__)\""
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.9.0+cu102\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxL6xzCgB6j4"
      },
      "source": [
        "###**Imports**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzR9qPQfB9-y",
        "outputId": "1a1a2ebf-fb0a-4898-c9c1-5c43741ab586"
      },
      "source": [
        "!pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n",
        "!pip install torch-sparse -f https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n",
        "!pip install torch-cluster -f https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n",
        "!pip install torch-geometric -f https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n",
        "\n",
        "!pip install -q path\n",
        "!pip install torchmetrics\n",
        "\n",
        "%matplotlib inline\n",
        "import os\n",
        "import numpy as np\n",
        "from path import Path\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torchmetrics import Accuracy, IoU\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.data import DataLoader\n",
        "from torch_geometric.datasets import ShapeNet\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from torch_geometric.utils import to_dense_batch\n",
        "\n",
        "import datetime\n",
        "import itertools\n",
        "import tensorflow\n",
        "import tensorboard\n",
        "from time import time\n",
        "from tensorboard import notebook\n",
        "from torchvision.utils import make_grid\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "%reload_ext tensorboard"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n",
            "Requirement already satisfied: torch-scatter in /usr/local/lib/python3.7/dist-packages (2.0.7)\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n",
            "Requirement already satisfied: torch-sparse in /usr/local/lib/python3.7/dist-packages (0.6.10)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-sparse) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy->torch-sparse) (1.19.5)\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n",
            "Requirement already satisfied: torch-cluster in /usr/local/lib/python3.7/dist-packages (1.5.9)\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.7/dist-packages (1.7.2)\n",
            "Requirement already satisfied: googledrivedownloader in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.11.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.5.1)\n",
            "Requirement already satisfied: rdflib in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (5.0.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.4.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: python-louvain in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (4.41.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.1.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.22.2.post1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric) (2.0.1)\n",
            "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx->torch-geometric) (4.4.2)\n",
            "Requirement already satisfied: isodate in /usr/local/lib/python3.7/dist-packages (from rdflib->torch-geometric) (0.6.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from rdflib->torch-geometric) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2021.5.30)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2.8.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (1.0.1)\n",
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.7/dist-packages (0.3.2)\n",
            "Requirement already satisfied: torch>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.9.0+cu102)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (20.9)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.3.1->torchmetrics) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->torchmetrics) (2.4.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8Xv57PDBtZU"
      },
      "source": [
        "###**Hyperparameters**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIy0Rj3tBwYz"
      },
      "source": [
        "hparams = {\n",
        "    'k': 3,\n",
        "    'num_classes': 16,\n",
        "    'lr': 1e-3,\n",
        "    'wd': 1e-3,\n",
        "    'bs': 16,\n",
        "    'num_workers': 2,\n",
        "    'shuffle_train': False,\n",
        "    'shuffle_valid': False,\n",
        "    'epochs': 20,\n",
        "    'schedule': False\n",
        "}"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pL5dRNFjCWdE"
      },
      "source": [
        "###**PointNet**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNll8lDaCWuy"
      },
      "source": [
        "class TNet(nn.Module):\n",
        "  def __init__(self, k=3):\n",
        "    super().__init__()\n",
        "    self.k = k\n",
        "    self.sharedMLP = nn.Sequential(\n",
        "        nn.Conv1d(in_channels=k, out_channels=64, kernel_size=1, bias=True),\n",
        "        nn.BatchNorm1d(64), \n",
        "        nn.ReLU(),\n",
        "        nn.Conv1d(in_channels=64, out_channels=128, kernel_size=1, bias=True),\n",
        "        nn.BatchNorm1d(128), \n",
        "        nn.ReLU(),\n",
        "        nn.Conv1d(in_channels=128, out_channels=1024, kernel_size=1, bias=True),\n",
        "        nn.BatchNorm1d(1024), \n",
        "        nn.ReLU()\n",
        "    )\n",
        "    self.FC = nn.Sequential(\n",
        "        nn.Linear(in_features=1024, out_features=512, bias=True),\n",
        "        nn.BatchNorm1d(512), \n",
        "        nn.ReLU(),\n",
        "        nn.Linear(in_features=512, out_features=256, bias=True),\n",
        "        nn.BatchNorm1d(256), \n",
        "        nn.ReLU(),\n",
        "        # nn.Dropout(p=0.7), only apply when overfitting\n",
        "        nn.Linear(in_features=256, out_features=k*k), \n",
        "    )\n",
        "\n",
        "  def forward(self, cloud_points):\n",
        "    bs = cloud_points.size(0)\n",
        "    x = self.sharedMLP(cloud_points)\n",
        "    # size: [batch size, 1024, # of points]\n",
        "    x = nn.MaxPool1d(x.size(-1))(x) # pool with kernel = # of points/batch\n",
        "    # size: [batch size, 1024, 1]\n",
        "    x = nn.Flatten(start_dim=1)(x) # flatten to get horizontal vector\n",
        "    # size: [batch size, 1024]\n",
        "    x = self.FC(x)\n",
        "    # diagonal matrices initialized, as many as batch size\n",
        "    init_matrix = torch.eye(self.k, requires_grad=True).repeat(bs,1,1)\n",
        "    if torch.cuda.is_available() and x.is_cuda:\n",
        "      init_matrix = init_matrix.cuda() # gets updated according to f.c. output\n",
        "    matrix = x.view(-1, self.k, self.k) + init_matrix\n",
        "    return matrix\n",
        "\n",
        "class Transform(nn.Module):\n",
        "   def __init__(self, k=3):\n",
        "        super().__init__()\n",
        "        self.k = k\n",
        "        # Input transform + First Shared MLP:\n",
        "        self.input_transform = TNet(k)\n",
        "        self.fc1 = nn.Sequential(\n",
        "          nn.Conv1d(in_channels=3, out_channels=64, kernel_size=1, bias=True),\n",
        "          nn.ReLU(),\n",
        "          nn.BatchNorm1d(64)\n",
        "        )\n",
        "        # Feature transform + Second Shared MLP: \n",
        "        self.feature_transform = TNet(k=64)\n",
        "        self.fc2 = nn.Sequential(\n",
        "          nn.Conv1d(in_channels=64, out_channels=128, kernel_size=1, bias=True),\n",
        "          nn.BatchNorm1d(128), \n",
        "          nn.ReLU(),\n",
        "          nn.Conv1d(in_channels=128, out_channels=1024, kernel_size=1, bias=True),\n",
        "          nn.BatchNorm1d(1024)\n",
        "        )\n",
        "\n",
        "   def forward(self, x):\n",
        "        bs = x.size(0)\n",
        "        # ------------------------------------------------------------\n",
        "        matrix3x3 = self.input_transform(x)\n",
        "        x = torch.bmm(torch.transpose(x,1,2),matrix3x3).transpose(1,2)\n",
        "        x = self.fc1(x)\n",
        "        # ------------------------------------------------------------\n",
        "        matrix64x64 = self.feature_transform(x)\n",
        "        y = torch.bmm(torch.transpose(x,1,2), matrix64x64).transpose(1,2) \n",
        "        x = self.fc2(y)\n",
        "        # Maxpool \n",
        "        y = nn.MaxPool1d(x.size(-1))(x)\n",
        "        \"\"\"\n",
        "        x = nn.Flatten(1)(x).repeat(n_points,1,1).transpose(0,2).transpose(0,1)\n",
        "        y = torch.cat((x, y.repeat(1,1,n_points)), 1)\n",
        "        \"\"\"\n",
        "        \n",
        "        global_features = x.view(bs,-1)\n",
        "        return y\n",
        "\n",
        "class PointNetModel(nn.Module):\n",
        "    def __init__(self, k=3, num_classes=16):\n",
        "        super().__init__()\n",
        "        self.k = k\n",
        "        # Transform + Last MLP\n",
        "        \n",
        "        self.transform = Transform(self.k)\n",
        "        '''\n",
        "        self.FC1 = nn.Linear(in_features=1024, out_features=512)\n",
        "        self.bn1 = nn.BatchNorm1d(512)\n",
        "        self.FC2 = nn.Linear(in_features=512, out_features=256)\n",
        "        self.bn2 = nn.BatchNorm1d(256)\n",
        "        self.FC3 = nn.Linear(in_features=256, out_features=num_classes)\n",
        "        self.dropout = nn.Dropout(p=0.3)\n",
        "        '''\n",
        "        self.fc1 = nn.Sequential(\n",
        "            nn.Linear(in_features=1024, out_features=512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_features=512, out_features=256),\n",
        "            nn.Dropout(p=0.3),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_features=256, out_features=num_classes),\n",
        "        )\n",
        "        \"\"\"\n",
        "        self.fc2 = nn.Sequential(\n",
        "            nn.Conv1d(in_channels=128, out_channels=128, kernel_size=1),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(in_channels=128, out_channels=num_classes, kernel_size=1)\n",
        "        )\n",
        "        \"\"\"\n",
        "    def forward(self, x):\n",
        "      '''\n",
        "      x = self.transform(x)\n",
        "      x = F.relu(self.bn1(self.FC1(x))) \n",
        "      x = F.relu(self.bn2(self.dropout(self.FC2(x)))) \n",
        "      output = self.FC3(x)\n",
        "      '''\n",
        "      x = self.transform(x)\n",
        "      output = self.fc1(x)\n",
        "      \n",
        "      return output, F.softmax(output,dim=1)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDmXBzwqDLq_"
      },
      "source": [
        "###**ShapeNet**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLedmTaqDSAU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "168affc9-7638-4d8a-a13e-ad04cff35f63"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "sn_train = ShapeNet(root='/content/drive/MyDrive/Dataset_ShapeNet/',split=\"train\",include_normals=False)\n",
        "sn_valid = ShapeNet(root='/content/drive/MyDrive/Dataset_ShapeNet/',split=\"val\",include_normals=False)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "v7l0onQoy_Nt",
        "outputId": "e8968fc8-0804-4457-f4f2-5160166670f8"
      },
      "source": [
        "def get_loader(data, \n",
        "               bs=1, \n",
        "               num_workers=2, \n",
        "               shuffle=False):\n",
        "  # Function to load ShapeNet split into a DataLoader object:\n",
        "  data_loader = DataLoader(data, \n",
        "                          batch_size=bs,\n",
        "                          shuffle=shuffle,\n",
        "                          num_workers=num_workers)\n",
        "  return data_loader\n",
        "\n",
        "device =  torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_loader = get_loader(sn_train)\n",
        "model = PointNetModel().to(device)\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "\n",
        "for i, data in enumerate(train_loader,1):\n",
        "  datos = data\n",
        "  targets = datos.category.to(device)\n",
        "  points = datos.pos.unsqueeze(2).to(device)\n",
        "  #targets = datos.category.to(device)\n",
        "  preds, probs = model(points)\n",
        "  print(preds.shape)\n",
        "  print(targets.shape)\n",
        "  #print(preds.squeeze(-1))\n",
        "  print(criterion(preds.squeeze(-1), targets))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-2d72ef2ca61f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m   \u001b[0mpoints\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m   \u001b[0;31m#targets = datos.category.to(device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m   \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-22c0625bcd95>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFC1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFC2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m       \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFC3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1845\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1847\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemm( handle, opa, opb, m, n, k, &alpha, a, lda, b, ldb, &beta, c, ldc)`"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyMOcUYCZ3RA"
      },
      "source": [
        "for i, data in enumerate(train_loader):\n",
        "  targets = []\n",
        "  counts = torch.unique(data.batch, return_counts=True)[1]\n",
        "  for i, subdata in enumerate(data.category):\n",
        "    targets.append(subdata.repeat(counts[i]))\n",
        "  targets = torch.cat(targets)\n",
        "  print(targets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RojHdeiKDYtB"
      },
      "source": [
        "###**Train Loop**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TLh4v9FDhWt"
      },
      "source": [
        "def get_loader(data, \n",
        "               bs=32, \n",
        "               num_workers=2, \n",
        "               shuffle=False):\n",
        "  # Function to load ShapeNet split into a DataLoader object:\n",
        "  data_loader = DataLoader(data, \n",
        "                          batch_size=bs,\n",
        "                          shuffle=shuffle,\n",
        "                          num_workers=num_workers)\n",
        "  return data_loader\n",
        "\n",
        "def train_epoch(model, \n",
        "                train_loader, \n",
        "                optimizer, \n",
        "                device, \n",
        "                criterion, \n",
        "                accuracy):\n",
        "  # List for epoch loss:\n",
        "  epoch_train_loss = []\n",
        "  # Model in train mode:\n",
        "  model.train()\n",
        "  # Metrics stored information reset:\n",
        "  accuracy.reset()\n",
        "  #iou.reset()\n",
        "  # Batch loop for training:\n",
        "  for i, data in enumerate(train_loader,1):\n",
        "      # Data retrieval from each bath:   \n",
        "      points = to_dense_batch(data.pos,batch=data.batch)[0].to(device).float().transpose(1,2)\n",
        "      targets = data.category.to(device)\n",
        "      # Forward pass:\n",
        "      preds, probs = model(points)\n",
        "      # Loss calculation + Backpropagation pass\n",
        "      optimizer.zero_grad()\n",
        "      loss = criterion(preds.squeeze(-1), targets).to(device)\n",
        "      epoch_train_loss.append(loss.item()) # save loss to later represent\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      # Batch metrics calculation:\n",
        "      accuracy.update(probs.squeeze(),targets)\n",
        "      #iou.update(probs.squeeze(), targets)\n",
        "  # Mean epoch metrics calculation:\n",
        "  mean_loss = np.mean(epoch_train_loss)\n",
        "  mean_acc = accuracy.compute().item()\n",
        "  #mean_iou = iou.compute().item()\n",
        "  # Print of all metrics:\n",
        "  print('Train loss: ', mean_loss, \"| Acc.: \", mean_acc)\n",
        "  return mean_loss, mean_acc\n",
        "\n",
        "def valid_epoch(model, \n",
        "                valid_loader, \n",
        "                scheduler,\n",
        "                schedule, \n",
        "                device,\n",
        "                criterion, \n",
        "                accuracy):\n",
        "  # List for epoch loss:\n",
        "  epoch_valid_loss = []\n",
        "  # Model in validation (evaluation) mode:\n",
        "  model.eval()\n",
        "  # Metrics stored information reset:\n",
        "  accuracy.reset()\n",
        "  #iou.reset()\n",
        "  # Batch loop for validation:\n",
        "  with torch.no_grad():\n",
        "    for i,data in enumerate(valid_loader,1):\n",
        "        # Data retrieval from each bath:   \n",
        "        #points = data.pos.unsqueeze(2).to(device)\n",
        "        points = to_dense_batch(data.pos,batch=data.batch)[0].to(device).float().transpose(1,2)\n",
        "        #targets = data.category.to(device)\n",
        "        # Forward pass:\n",
        "        preds, probs = model(points)\n",
        "        # Loss calculation + Backpropagation pass\n",
        "        loss = criterion(preds.squeeze(-1), targets.repeat(points.shape[0])).to(device)\n",
        "        epoch_valid_loss.append(loss.item())\n",
        "        # Batch metrics calculation:\n",
        "        accuracy.update(probs.squeeze(),targets)\n",
        "        #iou.update(probs.squeeze(),targets)\n",
        "  # Mean epoch metrics calculation:\n",
        "  mean_loss = np.mean(epoch_valid_loss)\n",
        "  mean_acc = accuracy.compute().item()\n",
        "  #mean_iou = iou.compute().item()\n",
        "  # Learnign rate adjustment with scheduler:\n",
        "  if schedule == True: scheduler.step(mean_loss)\n",
        "  # Print of all metrics:\n",
        "  print('Valid loss: ', mean_loss, \"| Acc.: \", mean_acc)\n",
        "  return mean_loss, mean_acc\n",
        "\n",
        "def fit(train_data, \n",
        "        valid_data,\n",
        "        k=3,\n",
        "        num_classes=16, \n",
        "        bs=128, \n",
        "        num_workers=2, \n",
        "        epochs=20, \n",
        "        lr=0.001,\n",
        "        schedule=False, \n",
        "        shuffle_train=True, \n",
        "        shuffle_valid=False, \n",
        "        model_filename=None):\n",
        "  # Data Loaders for train and validation:\n",
        "  train_loader = get_loader(data=train_data, \n",
        "                            bs=bs, \n",
        "                            num_workers=num_workers, \n",
        "                            shuffle=shuffle_train)\n",
        "  valid_loader = get_loader(data=valid_data, \n",
        "                            bs=bs, \n",
        "                            num_workers=num_workers, \n",
        "                            shuffle=shuffle_valid)\n",
        "  \n",
        "  # Features:\n",
        "  device =  torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "  model = PointNetModel(k=k, num_classes=num_classes).to(device)\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "  scheduler = ReduceLROnPlateau(optimizer, patience=5)\n",
        "  criterion = nn.CrossEntropyLoss().to(device)\n",
        "  # Metrics:\n",
        "  accuracy = Accuracy(average='micro', compute_on_step=False).to(device)\n",
        "  #iou = IoU(num_classes=num_classes, absent_score=1, compute_on_step=False).to(device)\n",
        "  # Tensorboard Block:\n",
        "    # Avoid tensorboard crashing when adding embeddings:\n",
        "  tensorflow.io.gfile = tensorboard.compat.tensorflow_stub.io.gfile \n",
        "  tensorboard_name = \"tensorboad\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + '.csv'\n",
        "  logdir = os.path.join(Path('/content/drive/MyDrive/Dataset_ShapeNet/'), tensorboard_name)\n",
        "  writer = SummaryWriter(log_dir=logdir) # writer for each epoch\n",
        "  #writer_best = SummaryWriter(log_dir=logdir) # writer for best IoU value\n",
        "  \n",
        "  # Lists for epoch metrics:\n",
        "  train_loss = []\n",
        "  valid_loss = []\n",
        "  train_macc = []\n",
        "  valid_macc = []\n",
        "  #train_miou = []  \n",
        "  #valid_miou = []\n",
        "  \n",
        "  # Initialize value for Acc (which is used to save the model of best performance)\n",
        "  min_macc = 0\n",
        "  # Start training:\n",
        "  print('Start training...')\n",
        "  for epoch in range(epochs):\n",
        "    print(\"Epoch: \", epoch)\n",
        "    # Training epoch:\n",
        "    epoch_train_loss, epoch_train_macc = train_epoch(model, \n",
        "                                                    train_loader, \n",
        "                                                    optimizer, \n",
        "                                                    device, \n",
        "                                                    criterion, \n",
        "                                                    accuracy)\n",
        "    # Validation epoch:\n",
        "    epoch_valid_loss, epoch_valid_macc= valid_epoch(model,\n",
        "                                                    valid_loader, \n",
        "                                                    scheduler, schedule, \n",
        "                                                    device, \n",
        "                                                    criterion, \n",
        "                                                    accuracy)\n",
        "    # Add epoch metrics to lists:\n",
        "    train_loss.append(epoch_train_loss)\n",
        "    valid_loss.append(epoch_valid_loss)\n",
        "    train_macc.append(epoch_train_macc)\n",
        "    valid_macc.append(epoch_valid_macc)\n",
        "    #train_miou.append(epoch_train_miou)\n",
        "    #valid_miou.append(epoch_valid_miou)\n",
        "    # Function to write metrics in selected tensorboard:\n",
        "    #def write_metric_tb(tb, label, metric, epoch):\n",
        "    #  tb.add_scalar(label, np.array(metric), epoch)\n",
        "      # Write training and validation loss in tensorboard\n",
        "    #write_metric_tb(writer, 'Train loss', epoch_train_loss, epoch)\n",
        "    #write_metric_tb(writer, 'Valid loss', epoch_valid_loss, epoch)\n",
        "      # Write mean IoU and accuracy in tensorboard\n",
        "    #write_metric_tb(writer, 'Train Accuracy', epoch_train_macc, epoch)\n",
        "    #write_metric_tb(writer, 'Valid Accuracy', epoch_valid_macc, epoch)\n",
        "    #write_metric_tb(writer, 'Train IoU', epoch_train_miou, epoch)\n",
        "    #write_metric_tb(writer, 'Valid IoU', epoch_valid_miou, epoch)\n",
        "      # Save model and write in tensorboard: best if condition for IoU is fullfilled:\n",
        "    if epoch_valid_macc > min_macc:\n",
        "      min_maccu = epoch_valid_macc\n",
        "      '''\n",
        "      # Write training and validation loss in tensorboard: best\n",
        "      write_best_metric_tb(writer_best, 'Train loss', epoch_train_loss, epoch)\n",
        "      write_best_metric_tb(writer_best, 'Valid loss', epoch_valid_loss, epoch)\n",
        "      # Write mean IoU and accuracy in tensorboard: best\n",
        "      write_best_metric_tb(writer_best, 'Train Accuracy', epoch_train_macc, epoch)\n",
        "      write_best_metric_tb(writer_best, 'Valid Accuracy', epoch_valid_macc, epoch)\n",
        "      write_best_metric_tb(writer_best, 'Train IoU', epoch_train_miou, epoch)\n",
        "      write_best_metric_tb(writer_best, 'Valid IoU', epoch_valid_miou, epoch)\n",
        "      '''\n",
        "      # Save model:\n",
        "      #filename = model_filename if model_filename is not None else 'model_'+datetime.datetime.now().strftime(\"%Y%m%d\")+'.pth'\n",
        "      #save_path = os.path.join(Path('/content/drive/MyDrive/Dataset_ShapeNet/'), filename)\n",
        "      #torch.save(model.state_dict(), save_path)\n",
        "      #print('Model with %d loss overwritten. Model with %d loss saved to %s' %(min_macc, epoch_valid_loss, save_path))\n",
        "    \n",
        "    print('---------------------------------------------------------------------------------------------------------')\n",
        "  \n",
        "  # Plot for Losses:  \n",
        "  fig = plt.figure()\n",
        "  epochs = len(train_loss)\n",
        "  plt.plot(range(epochs), train_loss, 'bo', label='Train loss', ms=3)\n",
        "  plt.plot(range(epochs), valid_loss, 'ro', label='Valid loss', ms=3)\n",
        "  plt.title('Training and Validation Loss')\n",
        "  plt.legend()\n",
        "  # Plots for Accuracy and IoU: \n",
        "  def print_metrics(metric1, metric2, label1, label2):\n",
        "    fig, ax1 = plt.subplots()\n",
        "    ax2 = ax1.twinx()\n",
        "    ax1.plot(range(epochs), metric1, 'go', ms=3)\n",
        "    ax2.plot(range(epochs), metric2, 'yo', ms=3)\n",
        "    ax1.set_xlabel('Epochs')\n",
        "    ax1.set_ylabel(str(label1), color='g')\n",
        "    ax2.set_ylabel(str(label2), color='y')\n",
        "  print_metrics(valid_macc, train_macc, 'Valid Point Accuracy', 'Train Point Accuracy')\n",
        "\n",
        "  %tensorboard --logdir logs"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOWBTZvyFuo4"
      },
      "source": [
        "###**Experiment**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tICFBjNrFx4M",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b5c952ea-3de9-4b89-beec-53221046d8d9"
      },
      "source": [
        "fit(sn_train, sn_valid, hparams['k'], hparams['num_classes'], hparams['bs'], hparams['num_workers'], hparams['epochs'], hparams['lr'], hparams['schedule'], hparams['shuffle_train'], hparams['shuffle_valid'])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start training...\n",
            "Epoch:  0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-c1f34e8b3901>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msn_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msn_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'k'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'num_classes'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'num_workers'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epochs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'schedule'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'shuffle_train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'shuffle_valid'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-10-02ec7501c8da>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(train_data, valid_data, k, num_classes, bs, num_workers, epochs, lr, schedule, shuffle_train, shuffle_valid, model_filename)\u001b[0m\n\u001b[1;32m    145\u001b[0m                                                     \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m                                                     \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m                                                     accuracy)\n\u001b[0m\u001b[1;32m    148\u001b[0m     \u001b[0;31m# Validation epoch:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     epoch_valid_loss, epoch_valid_macc= valid_epoch(model,\n",
            "\u001b[0;32m<ipython-input-10-02ec7501c8da>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, train_loader, optimizer, device, criterion, accuracy)\u001b[0m\n\u001b[1;32m     29\u001b[0m       \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m       \u001b[0;31m# Forward pass:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m       \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m       \u001b[0;31m# Loss calculation + Backpropagation pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-5da30568667a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    123\u001b[0m       '''\n\u001b[1;32m    124\u001b[0m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m       \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1845\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1847\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemm( handle, opa, opb, m, n, k, &alpha, a, lda, b, ldb, &beta, c, ldc)`"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxsKE8cI10mT"
      },
      "source": [
        "1+1"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}