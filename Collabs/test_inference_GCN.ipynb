{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test_inference_GCN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzVUqwcqGBc_"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ox_HH3uFGJk6"
      },
      "source": [
        "## Installations and imports"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJrQ7pzvGLVV"
      },
      "source": [
        "### Installations\n",
        "As some libraries that are not in the default version in colab are used, it is necessary to install them"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70I6YY3IGBOz"
      },
      "source": [
        "!pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n",
        "!pip install torch-sparse -f https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n",
        "!pip install torch-cluster -f https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n",
        "!pip install torch-geometric -f https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n",
        "\n",
        "!pip install torchmetrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xap2BPolGPN2"
      },
      "source": [
        "### Imports\n",
        "In the next snippet of code there are all the imports necessaries for the project and the tensorboard is initialized."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlT9KejzF6F0"
      },
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "from torchmetrics import Accuracy\n",
        "\n",
        "from torch_geometric.nn import GCNConv, global_max_pool\n",
        "from torch_geometric.data import DataLoader\n",
        "from torch_geometric.datasets import ModelNet\n",
        "from torch_geometric.transforms import SamplePoints, NormalizeScale, KNNGraph, Compose"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55Sn5CSRGgiE"
      },
      "source": [
        "## Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdghrIHFGX-2"
      },
      "source": [
        "hparams = {\n",
        "    'bs': 1,\n",
        "    'device': torch.device('cuda:0' if torch.cuda.is_available() else 'cpu'),\n",
        "    'drive_root': '/content/drive/MyDrive/Dataset/ModelNet',\n",
        "    'normalize_scale': True, \n",
        "    'fixed_num_of_points': 1024,\n",
        "    'model_log': '/content/drive/MyDrive/GCN/GCN3_DFSc.pt', \n",
        "    'k': 3,\n",
        "    'num_classes': 10,\n",
        "    'level': 3,\n",
        "    'dropout': 0.3\n",
        "}"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5Xagjn7G9HG"
      },
      "source": [
        "#Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5Y0hI9AGmAN"
      },
      "source": [
        "class GCN(nn.Module):\n",
        "  def __init__(self, k=3, num_classes=10, level=3, dropout=0.3):\n",
        "      super().__init__()\n",
        "      self.k = k\n",
        "      self.level = level\n",
        "      self.classes = num_classes\n",
        "      self.last_hidden_layer = 8 * 2**self.level\n",
        "\n",
        "      self.conv1 = GCNConv(self.k, 16)\n",
        "      self.conv2 = GCNConv(16, 32)\n",
        "      self.conv3 = GCNConv(32, 64)\n",
        "      self.fc = nn.Linear(self.last_hidden_layer, self.classes)\n",
        "\n",
        "      self.bn1 = nn.BatchNorm1d(16)\n",
        "      self.bn2 = nn.BatchNorm1d(32)\n",
        "      self.bn3 = nn.BatchNorm1d(64)\n",
        "\n",
        "      self.dropout = nn.Dropout(p=dropout) if dropout is not None else None\n",
        "\n",
        "  def forward(self, x, edge_index, batch):\n",
        "      # 1. Obtain node embeddings\n",
        "      x = self.conv1(x, edge_index)\n",
        "      x = self.dropout(x) if self.level == 1 and self.dropout is not None else x\n",
        "      x = F.relu(self.bn1(x))\n",
        "\n",
        "      if self.level >= 2:\n",
        "          x = self.conv2(x, edge_index)\n",
        "          x = self.dropout(x) if self.level == 2 and self.dropout is not None else x\n",
        "          x = F.relu(self.bn2(x))\n",
        "\n",
        "      if self.level >= 3:\n",
        "          x = self.conv3(x, edge_index)\n",
        "          x = self.dropout(x) if self.level == 3 and self.dropout is not None else x\n",
        "          x = F.relu(self.bn3(x))\n",
        "\n",
        "      # 2. Readout layer: Aggregate node embeddings into a unified graph embedding\n",
        "      x = global_max_pool(x, batch)  # [batch_size=32, hidden_channels=64]\n",
        "\n",
        "      # 3. Apply a final classifier\n",
        "      x = self.fc(x)\n",
        "\n",
        "      return x, F.softmax(x, dim=1)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujIklr9dHDrE"
      },
      "source": [
        "# Dataset\n",
        "First of all, it is necessary to make the drive folder with the dataset available to this collab in order not to download it every time. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVBCRddVHBam",
        "outputId": "ea127e3b-4187-4e10-d0c8-7faa9cd740e9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qiOOunaPHWg_"
      },
      "source": [
        "## Transformations\n",
        "In this project is necessary to use some transformations to either normalize the data or to perform data augmentation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R35O3PhtHIRG"
      },
      "source": [
        "def get_pre_transformation(number_points=1024):\n",
        "    return SamplePoints(num=number_points)\n",
        "\n",
        "def get_transformation(normalize_scale):\n",
        "    if normalize_scale:  \n",
        "      return Compose([NormalizeScale(), KNNGraph(k=9, loop=True, force_undirected=True)])\n",
        "    else:\n",
        "        return KNNGraph(k=9, loop=True, force_undirected=True)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8srb8N5sHcFl"
      },
      "source": [
        "## Test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Ch8-jtxHerM"
      },
      "source": [
        "def get_dataset(root, number_points=1024, normalize_scale=True):\n",
        "    \n",
        "    test_dataset = ModelNet(root=root, name=\"10\", train=False, pre_transform=get_pre_transformation(number_points), transform=get_transformation(normalize_scale))\n",
        "    return test_dataset"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FvKUWu5uHt2D"
      },
      "source": [
        "## Helper functions\n",
        "As there are some functionalities that are used by different functions or can be used in the future, a list of helpers fucntions has been created"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KBx8IVuHyum"
      },
      "source": [
        "# Method to visualize a cloud point\n",
        "def visualize_point_cloud(point_cloud):\n",
        "    edge_index, points, y = point_cloud\n",
        "    edge_x = [], edge_y = [], edge_z = []\n",
        "    edges_index = edge_index[1].numpy().T\n",
        "    real_points = points[1].numpy()\n",
        "\n",
        "    # Get coordinates from adjacency matrix\n",
        "    for i, edge in enumerate(edges_index):\n",
        "        x0, y0, z0 = real_points[edge[0]]\n",
        "        x1, y1, z1 = real_points[edge[1]]\n",
        "        edge_x.extend([x0, x1, None])\n",
        "        edge_y.extend([y0, y1, None])\n",
        "        edge_z.extend([z0, z1, None])\n",
        "\n",
        "    edge_trace = go.Scatter3d(\n",
        "        x=edge_x, y=edge_y, z=edge_z,\n",
        "        line=dict(width=0.5, color='#888'),\n",
        "        hoverinfo='none',\n",
        "        mode='lines')\n",
        "\n",
        "    node_x = [], node_y = [], node_z = []\n",
        "    # Get node coordinates\n",
        "    for node in real_points:\n",
        "        x, y, z = node\n",
        "        node_x.append(x)\n",
        "        node_y.append(y)\n",
        "        node_z.append(z)\n",
        "\n",
        "    node_trace = go.Scatter3d(\n",
        "        x=node_x, y=node_y, z=node_z,\n",
        "        mode='markers',\n",
        "        hoverinfo='text',\n",
        "        marker=dict(\n",
        "            showscale=True,\n",
        "            # color scale options\n",
        "            # 'Greys' | 'YlGnBu' | 'Greens' | 'YlOrRd' | 'Bluered' | 'RdBu' |\n",
        "            # 'Reds' | 'Blues' | 'Picnic' | 'Rainbow' | 'Portland' | 'Jet' |\n",
        "            # 'Hot' | 'Blackbody' | 'Earth' | 'Electric' | 'Viridis' |\n",
        "            colorscale='YlGnBu',\n",
        "            reversescale=True,\n",
        "            color=[],\n",
        "            size=10,\n",
        "            colorbar=dict(\n",
        "                thickness=15,\n",
        "                title='Node Connections',\n",
        "                xanchor='left',\n",
        "                titleside='right'\n",
        "            ),\n",
        "            line_width=2))\n",
        "\n",
        "    fig = go.Figure(data=[edge_trace, node_trace],\n",
        "                    layout=go.Layout(\n",
        "                        title='<br>Network graph made with Python',\n",
        "                        titlefont_size=16,\n",
        "                        showlegend=False,\n",
        "                        hovermode='closest',\n",
        "                        margin=dict(b=20, l=5, r=5, t=40),\n",
        "                        annotations=[dict(\n",
        "                            showarrow=False,\n",
        "                            xref=\"paper\", yref=\"paper\",\n",
        "                            x=0.005, y=-0.002)],\n",
        "                        xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
        "                        yaxis=dict(showgrid=False, zeroline=False, showticklabels=False))\n",
        "                    )\n",
        "    fig.show()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n15grcewICTi"
      },
      "source": [
        "# Testing inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r24Vc67jIL0u"
      },
      "source": [
        "def test(test_data, model_state_dict_root):\n",
        "    test_loader = DataLoader(test_data, batch_size=hparams['bs'], shuffle=False)\n",
        "    model = GCN(hparams['k'], hparams['num_classes'], hparams['level'], hparams['dropout']).to(hparams['device'])\n",
        "\n",
        "    accuracy = Accuracy(average='micro', compute_on_step=False).to(hparams['device'])\n",
        "    model.load_state_dict(torch.load(model_state_dict_root))\n",
        "    model.eval()\n",
        "    # Metric stored information reset:\n",
        "    accuracy.reset()\n",
        "    # Batch loop for validation:\n",
        "    with torch.no_grad():\n",
        "        for i, data in enumerate(test_loader, 1):\n",
        "            # Data retrieval from each bath:\n",
        "            points = data.pos.to(hparams['device'])\n",
        "            targets = data.y.to(hparams['device'])\n",
        "\n",
        "            # Forward pass:\n",
        "            preds, probs = model(points, data.edge_index.to(hparams['device']), data.batch.to(hparams['device']))  \n",
        "\n",
        "            # Batch metrics calculation:\n",
        "            accuracy.update(probs, targets)\n",
        "\n",
        "    mean_accu = accuracy.compute().item()\n",
        "    # Print of all metrics:\n",
        "    print(\"Test Acc.: \", mean_accu)\n",
        "    return mean_accu"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGiUVrTyIQfF",
        "outputId": "0271b35c-2a57-4eac-a25c-703aeb8dbc49"
      },
      "source": [
        "test_dataset = get_dataset(hparams['drive_root'], hparams['fixed_num_of_points'], hparams['normalize_scale'])\n",
        "test(test_dataset, hparams['model_log']) "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Acc.:  0.8777533173561096\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8777533173561096"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    }
  ]
}