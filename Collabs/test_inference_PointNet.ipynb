{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test_inference_PointNet.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzVUqwcqGBc_"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ox_HH3uFGJk6"
      },
      "source": [
        "## Installations and imports"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJrQ7pzvGLVV"
      },
      "source": [
        "### Installations\n",
        "As some libraries that are not in the default version in colab are used, it is necessary to install them"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70I6YY3IGBOz",
        "outputId": "048166d5-b585-4483-c2c4-c0bc9db0fe87"
      },
      "source": [
        "!pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n",
        "!pip install torch-sparse -f https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n",
        "!pip install torch-cluster -f https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n",
        "!pip install torch-geometric -f https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n",
        "\n",
        "!pip install torchmetrics"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n",
            "Requirement already satisfied: torch-scatter in /usr/local/lib/python3.7/dist-packages (2.0.7)\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n",
            "Requirement already satisfied: torch-sparse in /usr/local/lib/python3.7/dist-packages (0.6.10)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-sparse) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy->torch-sparse) (1.19.5)\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n",
            "Requirement already satisfied: torch-cluster in /usr/local/lib/python3.7/dist-packages (1.5.9)\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.7/dist-packages (1.7.2)\n",
            "Requirement already satisfied: rdflib in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (5.0.0)\n",
            "Requirement already satisfied: googledrivedownloader in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.4)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.4.7)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.22.2.post1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.11.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.5.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.23.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.1.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: python-louvain in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.15)\n",
            "Requirement already satisfied: isodate in /usr/local/lib/python3.7/dist-packages (from rdflib->torch-geometric) (0.6.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from rdflib->torch-geometric) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (1.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric) (2.0.1)\n",
            "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx->torch-geometric) (4.4.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2018.9)\n",
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.7/dist-packages (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.19.5)\n",
            "Requirement already satisfied: torch>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.9.0+cu102)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (20.9)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.3.1->torchmetrics) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->torchmetrics) (2.4.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xap2BPolGPN2"
      },
      "source": [
        "### Imports\n",
        "In the next snippet of code there are all the imports necessaries for the project and the tensorboard is initialized."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlT9KejzF6F0"
      },
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "from torchmetrics import Accuracy\n",
        "\n",
        "from torch_geometric.data import DataLoader\n",
        "from torch_geometric.utils import to_dense_batch\n",
        "from torch_geometric.datasets import ModelNet\n",
        "from torch_geometric.transforms import SamplePoints, NormalizeScale"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55Sn5CSRGgiE"
      },
      "source": [
        "## Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdghrIHFGX-2"
      },
      "source": [
        "hparams = {\n",
        "    'bs': 1,\n",
        "    'device': torch.device('cuda:0' if torch.cuda.is_available() else 'cpu'),\n",
        "    'drive_root': '/content/drive/MyDrive/Dataset/ModelNet',\n",
        "    'normalize_scale': True, \n",
        "    'fixed_num_of_points': 1024,\n",
        "    'model_log': '/content/drive/MyDrive/Adapt/pointNet_normalized_flip_rotation_0.3_Adam_OneCycleLR.pt', \n",
        "    'k': 3,\n",
        "    'num_classes': 10,\n",
        "    'dropout': 0.3\n",
        "}"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5Xagjn7G9HG"
      },
      "source": [
        "#Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5Y0hI9AGmAN"
      },
      "source": [
        "class TNet(nn.Module):\n",
        "  def __init__(self, k=3):\n",
        "    super().__init__()\n",
        "    self.k = k\n",
        "    \n",
        "    self.Conv1 = nn.Conv1d(in_channels=k, out_channels=64, kernel_size=1)\n",
        "    self.bn1 = nn.BatchNorm1d(64) \n",
        "    self.Conv2 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=1)\n",
        "    self.bn2 = nn.BatchNorm1d(128)\n",
        "    self.Conv3 = nn.Conv1d(in_channels=128, out_channels=1024, kernel_size=1)\n",
        "    self.bn3 = nn.BatchNorm1d(1024)\n",
        "\n",
        "    self.FC1 = nn.Linear(in_features=1024, out_features=512)\n",
        "    self.bn4 = nn.BatchNorm1d(512)\n",
        "    self.FC2 = nn.Linear(in_features=512, out_features=256)\n",
        "    self.bn5 = nn.BatchNorm1d(256)\n",
        "\n",
        "    self.FC3 = nn.Linear(in_features=256, out_features=k*k)\n",
        "\n",
        "  def forward(self, cloud_points):\n",
        "    bs = cloud_points.size(0)\n",
        "\n",
        "    x = F.relu(self.bn1(self.Conv1(cloud_points)))\n",
        "    x = F.relu(self.bn2(self.Conv2(x)))\n",
        "    x = F.relu(self.bn3(self.Conv3(x)))\n",
        "\n",
        "    # size: [batch size, 1024, # of points]\n",
        "    x = nn.MaxPool1d(x.size(-1))(x) # pool with kernel = # of points/batch\n",
        "    # size: [batch size, 1024, 1]\n",
        "    x = x.view(bs,-1) # flatten to get horizontal vector\n",
        "\n",
        "    # size: [batch size, 1024]\n",
        "    x = F.relu(self.bn4(self.FC1(x)))\n",
        "    x = F.relu(self.bn5(self.FC2(x)))\n",
        "\n",
        "    # diagonal matrices initialized, as many as batch size\n",
        "    init_matrix = torch.eye(self.k, requires_grad=True).repeat(bs,1,1)\n",
        "    if x.is_cuda:\n",
        "      init_matrix = init_matrix.cuda() # gets updated according to f.c. output\n",
        "    matrix = self.FC3(x).view(-1, self.k, self.k) + init_matrix\n",
        "    return matrix\n",
        "\n",
        "class Transform(nn.Module):\n",
        "   def __init__(self, k=3):\n",
        "        super().__init__()\n",
        "        self.input_transform = TNet(k)\n",
        "        self.feature_transform = TNet(k=64)\n",
        "\n",
        "        self.Conv1 = nn.Conv1d(in_channels=3, out_channels=64, kernel_size=1)\n",
        "        self.Conv2 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=1)\n",
        "        self.Conv3 = nn.Conv1d(in_channels=128, out_channels=1024, kernel_size=1)\n",
        "\n",
        "        self.bn1 = nn.BatchNorm1d(64)\n",
        "        self.bn2 = nn.BatchNorm1d(128)\n",
        "        self.bn3 = nn.BatchNorm1d(1024)\n",
        "\n",
        "   def forward(self, x):\n",
        "        bs = x.size(0)\n",
        "\n",
        "        matrix3x3 = self.input_transform(x)\n",
        "        x = torch.bmm(torch.transpose(x,1,2),matrix3x3).transpose(1,2)\n",
        "        x = F.relu(self.bn1(self.Conv1(x)))\n",
        "        \n",
        "        matrix64x64 = self.feature_transform(x)\n",
        "        x = torch.bmm(torch.transpose(x,1,2), matrix64x64).transpose(1,2) \n",
        "        x = F.relu(self.bn2(self.Conv2(x)))\n",
        "        x = self.bn3(self.Conv3(x))\n",
        "\n",
        "        x = nn.MaxPool1d(x.size(-1))(x)\n",
        "        global_features = x.view(bs,-1)\n",
        "        return global_features\n",
        "\n",
        "class PointNetModel(nn.Module):\n",
        "    def __init__(self, k=3, num_classes=16, dropout=0.3):\n",
        "        super().__init__()\n",
        "        self.transform = Transform(k)\n",
        "\n",
        "        self.FC1 = nn.Linear(in_features=1024, out_features=512)\n",
        "        self.bn1 = nn.BatchNorm1d(512)\n",
        "        self.FC2 = nn.Linear(in_features=512, out_features=256)\n",
        "        self.bn2 = nn.BatchNorm1d(256)\n",
        "        self.FC3 = nn.Linear(in_features=256, out_features=num_classes)\n",
        "        self.dropout = nn.Dropout(p=0.3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        global_features = self.transform(x)\n",
        "        x = F.relu(self.bn1(self.FC1(global_features)))\n",
        "        x = self.FC2(x)\n",
        "        # apply dropout if exists\n",
        "        x = self.dropout(x) if self.dropout is not None else x\n",
        "        x = F.relu(self.bn2(x))\n",
        "        output = self.FC3(x)\n",
        "        return output, F.softmax(output,dim=1)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujIklr9dHDrE"
      },
      "source": [
        "# Dataset\n",
        "First of all, it is necessary to make the drive folder with the dataset available to this collab in order not to download it every time. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVBCRddVHBam",
        "outputId": "80d67120-021c-43fc-aa9f-3216eba27937"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qiOOunaPHWg_"
      },
      "source": [
        "## Transformations\n",
        "In this project is necessary to use some transformations to either normalize the data or to perform data augmentation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R35O3PhtHIRG"
      },
      "source": [
        "def get_pre_transformation(number_points=1024):\n",
        "    return SamplePoints(num=number_points)\n",
        "\n",
        "def get_transformation(normalize_scale):\n",
        "    if normalize_scale:  \n",
        "      return NormalizeScale()\n",
        "    else:\n",
        "        return None"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8srb8N5sHcFl"
      },
      "source": [
        "## Test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Ch8-jtxHerM"
      },
      "source": [
        "def get_dataset(root, number_points=1024, normalize_scale=True):\n",
        "    \n",
        "    test_dataset = ModelNet(root=root, name=\"10\", train=False, pre_transform=get_pre_transformation(number_points), transform=get_transformation(normalize_scale))\n",
        "    return test_dataset"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FvKUWu5uHt2D"
      },
      "source": [
        "## Helper functions\n",
        "As there are some functionalities that are used by different functions or can be used in the future, a list of helpers fucntions has been created"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KBx8IVuHyum"
      },
      "source": [
        "# Method to visualize a cloud point\n",
        "def visualize_point_cloud(point_cloud):\n",
        "    points, y = point_cloud\n",
        "    fig = go.Figure(data=[go.Mesh3d(x=points[1][:, 0], y=points[1][:, 1], z=points[1][:, 2], mode='markers', marker=dict(size=3, opacity=1))])\n",
        "    fig.show()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n15grcewICTi"
      },
      "source": [
        "# Testing inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r24Vc67jIL0u"
      },
      "source": [
        "def test(test_data, model_state_dict_root):\n",
        "    test_loader = DataLoader(test_data, batch_size=hparams['bs'], shuffle=False)\n",
        "    model = PointNetModel(hparams['k'], hparams['num_classes'], hparams['dropout']).to(hparams['device'])\n",
        "\n",
        "    accuracy = Accuracy(average='micro', compute_on_step=False).to(hparams['device'])\n",
        "    model.load_state_dict(torch.load(model_state_dict_root))\n",
        "    model.eval()\n",
        "    # Metric stored information reset:\n",
        "    accuracy.reset()\n",
        "    # Batch loop for validation:\n",
        "    with torch.no_grad():\n",
        "        for i, data in enumerate(test_loader, 1):\n",
        "            # Data retrieval from each bath:\n",
        "            points = to_dense_batch(data.pos, batch=data.batch)[0].to(hparams['device']).float().transpose(1, 2)\n",
        "            targets = data.y.to(hparams['device'])\n",
        "\n",
        "            # Forward pass:\n",
        "            preds, probs = model(points)\n",
        "\n",
        "            # Batch metrics calculation:\n",
        "            accuracy.update(probs, targets)\n",
        "\n",
        "    mean_accu = accuracy.compute().item()\n",
        "    # Print of all metrics:\n",
        "    print(\"Test Acc.: \", mean_accu)\n",
        "    return mean_accu"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGiUVrTyIQfF",
        "outputId": "03189579-2bb5-4435-def6-26c6151a887a"
      },
      "source": [
        "test_dataset = get_dataset(hparams['drive_root'], hparams['fixed_num_of_points'], hparams['normalize_scale'])\n",
        "test(test_dataset, hparams['model_log']) "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:652: UserWarning:\n",
            "\n",
            "Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test Acc.:  0.9240087866783142\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9240087866783142"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    }
  ]
}